{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da089df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023, Acadential, All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca922e1",
   "metadata": {},
   "source": [
    "# 11-7. Learning Rate Scheduler\n",
    "\n",
    "저희가 이론편에서 살펴보았던 Learning Rate Scheduler는 다음과 같습니다:\n",
    "\n",
    "1. Step LR\n",
    "2. Exponential LR\n",
    "3. Cosine Annealing LR\n",
    "4. Cosine Annealing with Warm Restarts LR\n",
    "5. Reduce on Plateau LR\n",
    "6. Chained scheduler (Linear scheduler with warmup)\n",
    "7. Huggingface LR scheduler (Cosine schedule with warmup)\n",
    "\n",
    "이번에는 이러한 Learning Rate Scheduler를 실제로 구현해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cedc07",
   "metadata": {},
   "source": [
    "## Pseudo Code\n",
    "\n",
    "아래 코드는 Learning Rate Scheduler에 대한 Pseudo Code입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pseudo Code\n",
    "import torch \n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import SGD\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=1e-4)\n",
    "scheduler = lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=30,\n",
    "    gamma=0.1\n",
    ")\n",
    "tbar = tqdm(dataset)\n",
    "for epoch in tbar:\n",
    "    train(...)\n",
    "    validate(...)\n",
    "    scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe71d05a",
   "metadata": {},
   "source": [
    "## Preliminary setup\n",
    "1. import modules\n",
    "2. define model\n",
    "3. define function for getting the current learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42744c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import SGD\n",
    "\n",
    "# Importing the model \n",
    "from src.model import NeuralNetwork\n",
    "\n",
    "# Importing the dataloaders\n",
    "from src.data import get_dataloaders\n",
    "\n",
    "# Importing the training and testing functions\n",
    "from src.train_val import train_loop, val_loop\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe9991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate model, loss function, and optimizer\n",
    "model = NeuralNetwork()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                            lr=0.001)\n",
    "# Define train and test dataloaders\n",
    "train_dataloader, test_dataloader = get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc99d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for retrieving the learning rate from the optimizer.\n",
    "def get_lr(optimizer):\n",
    "    return optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf52c45",
   "metadata": {},
   "source": [
    "## Step LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e8bd8",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f6ed6a",
   "metadata": {},
   "source": [
    "역할: Step LR Scheduler은 step_size마다 Learning Rate에 gamma을 곱해줍니다.\n",
    "\n",
    "즉, 아래 예시에서 step_size=30, gamma=0.1의 경우 매 30 epoch마다 learning rate을 1/10으로 줄여주는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa8b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step LR을 적용한 예시 코드\n",
    "# 100 epoch을 실제로 학습을 돌리기에는 학습 시간이 걸리므로 실제로 돌려보지는 않고\n",
    "# 다음 Cell에 있는 코드를 돌려서 Learning의 변화를 확인해보도록 하겠습니다.\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "\n",
    "lr_list = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    \n",
    "    model.train()\n",
    "    # Train Loop\n",
    "    train_losses = train_loop(model, train_dataloader, loss_fn, optimizer)\n",
    "    \n",
    "    model.eval()\n",
    "    # Validation Loop\n",
    "    test_loss, test_acc = val_loop(model, test_dataloader, loss_fn)\n",
    "    \n",
    "    scheduler.step()  # Step LR의 경우, Epoch 마다 scheduler.step()을 호출해야 합니다.\n",
    "    lr_list.append(get_lr(optimizer))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ff852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step LR에서는 Learning Rate이 어떻게 변하는지 확인해보겠습니다.\n",
    "\n",
    "lr_list = []\n",
    "lr_list.append(get_lr(optimizer))\n",
    "tbar = tqdm(range(100))\n",
    "for epoch in tbar:\n",
    "    # train(...)\n",
    "    # validate(...)\n",
    "    scheduler.step()\n",
    "    lr_list.append(get_lr(optimizer))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8fc028",
   "metadata": {},
   "source": [
    "### Plotting LR w.r.t Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e9fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lr_list)\n",
    "plt.title(\"Step LR\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebbc6e6",
   "metadata": {},
   "source": [
    "## Exponential LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94be369",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211afc85",
   "metadata": {},
   "source": [
    "역할: Exponential LR은 매 epoch마다 Learning Rate에 gamma을 곱해줍니다.\n",
    "\n",
    "즉, 아래 예시에서 gamma=0.9의 경우 매 epoch마다 learning rate에 0.9을 곱해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cec36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential LR Scheduler을 적용한 예시 코드\n",
    "# Step LR과 사용법이 동일합니다.\n",
    "# 마찬가지로 학습 시간이 조금 걸리니 실제로 돌려보지는 않고 다음 Cell에 있는 코드만 실행해주세요.\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "\n",
    "lr_list = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    \n",
    "    model.train()\n",
    "    # Train Loop\n",
    "    train_losses = train_loop(model, train_dataloader, loss_fn, optimizer)\n",
    "    \n",
    "    model.eval()\n",
    "    # Validation Loop\n",
    "    test_loss, test_acc = val_loop(model, test_dataloader, loss_fn)\n",
    "    \n",
    "    scheduler.step()  # Step LR의 경우, Epoch 마다 scheduler.step()을 호출해야 합니다.\n",
    "    lr_list.append(get_lr(optimizer))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad80c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(get_lr(optimizer))\n",
    "tbar = tqdm(range(100))\n",
    "for epoch in tbar:\n",
    "    # train(...)\n",
    "    # validate(...)\n",
    "    scheduler.step()\n",
    "    lr_list.append(get_lr(optimizer))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fd3526",
   "metadata": {},
   "source": [
    "### Plotting LR w.r.t Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lr_list)\n",
    "plt.title(\"Exponential LR Plotting LR w.r.t Epochs\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753cb275",
   "metadata": {},
   "source": [
    "## Cosine Annealing LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c18231",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c3dfb4",
   "metadata": {},
   "source": [
    "역할: T_max의 주기를 가진 Cosine 함수로 Learning Rate을 scheduling합니다.\n",
    "\n",
    "-  Optimizer에서 지정된 learning_rate이 곧 eta_max가 됩니다.\n",
    "    - 즉, T_cur = N x T_max 때마다 learning_rate == eta_max.\n",
    "- eta_min은 minimum learning rate입니다\n",
    "    - 즉, T_cur = N x T_max + T_max // 2 때마다 learning_rate == eta_min.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e3a83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf260ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                           T_max=2,\n",
    "                                           eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cccc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Annealing LR Scheduler을 적용한 예시 코드\n",
    "# Step LR과 사용법이 동일해서 Step LR을 참고하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0230ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(get_lr(optimizer))\n",
    "tbar = tqdm(range(100))\n",
    "for epoch in tbar:\n",
    "    # train(...)\n",
    "    # validate(...)\n",
    "    scheduler.step()\n",
    "    lr_list.append(get_lr(optimizer))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b918d0f",
   "metadata": {},
   "source": [
    "### Plotting LR w.r.t Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d327aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lr_list)\n",
    "plt.title(\"Cosine Annealing LR Plotting LR w.r.t Epochs\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505eff0",
   "metadata": {},
   "source": [
    "## Cosine Annealing with Warm Restarts LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08573aa",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a2180",
   "metadata": {},
   "source": [
    "역할: Cosine Annealing with Warm Restarts은 Cosine 함수로 줄어다가 다시 Max LR로 주기적으로 Restart하도록 Scheduling하는 방법입니다.\n",
    "\n",
    "-  Optimizer에서 지정된 learning_rate이 곧 eta_max가 됩니다.\n",
    "    - 즉, T_cur = N x T_max 때마다 learning_rate == eta_max.\n",
    "- eta_min은 minimum learning rate입니다.\n",
    "    - 즉, T_cur = N x T_max + T_max // 2 때마다 learning_rate == eta_min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,\n",
    "                                                     T_0=1,\n",
    "                                                     T_mult=2,\n",
    "                                                     eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Annealing LR with WarmRestarts Scheduler도\n",
    "# Step LR과 사용법이 동일해서 Step LR을 참고하면 됩니다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(get_lr(optimizer))\n",
    "tbar = tqdm(range(100))\n",
    "for epoch in tbar:\n",
    "    # train(...)\n",
    "    # validate(...)\n",
    "    scheduler.step()\n",
    "    lr_list.append(get_lr(optimizer))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0404f",
   "metadata": {},
   "source": [
    "### Plotting LR w.r.t Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff37305",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lr_list)\n",
    "plt.title(\"Cosine Annealing with Warm Restarts LR\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab7bec",
   "metadata": {},
   "source": [
    "## Reduce on Plateau LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb544467",
   "metadata": {},
   "source": [
    "역할: Reduece on Plateau LR은 앞에서 살펴보았던 LR Scheduler와는 다르게 특정 조건이 만족되었을 때 LR을 감소시키는 방식입니다. 이 방식은 특정 epoch동안 성능이 향상되지 않을 때 LR을 감소시키는 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be581294",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c3c129",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                          mode=\"min\",\n",
    "                                          factor=0.1,\n",
    "                                          patience=10,\n",
    "                                          threshold=0.0001,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada0678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce LR on Plateau을 Epoch 단위로 LR Scheduling 할시\n",
    "# 기존의 Step LR Scheduler와 동일하게 사용됩니다.\n",
    "\n",
    "train_loss_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "\n",
    "lr_list = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    \n",
    "    model.train()\n",
    "    # Train Loop\n",
    "    train_losses = train_loop(model, train_dataloader, loss_fn, optimizer)\n",
    "    \n",
    "    model.eval()\n",
    "    # Validation Loop\n",
    "    test_loss, test_acc = val_loop(model, test_dataloader, loss_fn)\n",
    "    \n",
    "    scheduler.step(test_loss)  # Reduce LR on Plateau의 경우 test_loss를 인자로 넣어줍니다.\n",
    "    lr_list.append(get_lr(optimizer))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8203916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(get_lr(optimizer))\n",
    "\n",
    "loss_list = np.random.rand(100)\n",
    "\n",
    "tbar = tqdm(range(100))\n",
    "for epoch in tbar:\n",
    "    # train(...)\n",
    "    # validate(...)\n",
    "    scheduler.step(loss_list[epoch])\n",
    "    lr_list.append(get_lr(optimizer))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e52e6c",
   "metadata": {},
   "source": [
    "### Plotting Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70df498",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(loss_list)\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa3aad1",
   "metadata": {},
   "source": [
    "### Plotting LR w.r.t Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85163c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lr_list)\n",
    "plt.title(\"Reduce on Plateau LR\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fd6b61",
   "metadata": {},
   "source": [
    "## Chained scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850a5fb",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af3434",
   "metadata": {},
   "source": [
    "역할: 여러 Learning Rate scheduler들을 차례대로 수행하고 싶은 경우 Chained Scheduler을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d8c9cf",
   "metadata": {},
   "source": [
    "###  Linear scheduler with warmup\n",
    "\n",
    "다음과 같은 LR schedule을 만들고 싶다고 가정해보겠습니다:\n",
    "- 먼저, Max Learning rate (1e-1)까지 Linear하게 10 epochs동안 증가했다가 (warmup 단계)\n",
    "- 나머지 epoch들에서는 exponentially하게 decay하는 LR schedule을 만들고 싶은 경우를 가정해보겠습니다.\n",
    "\n",
    "위 Schedule은 ChainedScheduler을 통해 다음과 같이 구현할 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8edb805",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46562aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "\n",
    "scheduler1 = lr_scheduler.LinearLR(optimizer, \n",
    "                                   start_factor=0.1,\n",
    "                                   end_factor=1.0,\n",
    "                                   total_iters=10)\n",
    "\n",
    "scheduler2 = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "scheduler = lr_scheduler.ChainedScheduler([scheduler1, scheduler2])\n",
    "lr_list.append(get_lr(optimizer))\n",
    "for epoch in tqdm(range(100)):\n",
    "    # train(...)\n",
    "    # validate(...)\n",
    "    scheduler.step()\n",
    "    lr_list.append(get_lr(optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f7933b",
   "metadata": {},
   "source": [
    "### Plotting LR w.r.t Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a26b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lr_list)\n",
    "plt.title(\"Chained LR (Linear LR + Exponential LR)\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"LR\")### Plotting LR w.r.t Epochs\n",
    "plt.axvline(10, color=\"r\", label=\"epoch=10\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a24f414",
   "metadata": {},
   "source": [
    "## Huggingface LR scheduler (Cosine Schedule with Warmup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94387871",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84661b39",
   "metadata": {},
   "source": [
    "Huggingface에서도 다양한 LR scheduler들을 제공합니다! \\\n",
    "한 가지 예시로는 Cosine Schedule with warmup 스케쥴입니다. \\\n",
    "transformers 라이브러리를 pip install하면 transformers.optimization에서 다양한 scheduler들을 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f07ac77",
   "metadata": {},
   "source": [
    "### Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5699c0",
   "metadata": {},
   "source": [
    "Documentation은 아래 링크에서 확인 가능합니다!\n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/optimizer_schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc364908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=1e-4)\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=10,\n",
    "    num_training_steps=90,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a7d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = []\n",
    "lr_list.append(get_lr(optimizer))\n",
    "for epoch in tqdm(range(100)):\n",
    "    # train(...)\n",
    "    # validate(...)\n",
    "    scheduler.step()\n",
    "    lr_list.append(get_lr(optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b49f3ba",
   "metadata": {},
   "source": [
    "### Plotting LR w.r.t Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df161405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(lr_list)\n",
    "plt.title(\"Cosine Schedule with Warmup\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"LR\")\n",
    "plt.axvline(10, color=\"r\", label=\"epoch=10\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e84b6b4",
   "metadata": {},
   "source": [
    "# 참고 사항\n",
    "\n",
    "학습할때 어떤 Learning Rate Scheduler가 최적의 Scheduler가 되는지는 알기 어렵습니다. \\\n",
    "따라서 Learning Rate Scheduler도 하나의 Hyperparameter로서 Grid Search와 같은 Hyperparameter Tuning을 통해서 최적의 Scheduler를 찾아야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9205699a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f206fd53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
